{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(\n",
    "    api_key=''\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T00:41:32.032535Z",
     "start_time": "2024-09-06T00:41:31.292891Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "# read training files\n",
    "\n",
    "with open('training_data/train_lf.json', 'r', encoding='utf-8') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "tot_prompt = \"Imagine five different experts answering this question. All experts will write down 1 step of their thinking and then share it with the group. Then all experts will go on to the next step, etc. If any expert realizes they're wrong at any point, then they leave. And show me the result in the end. \\nThe question is:\\n\\nYou are a recommender system. Given the historical data and some details, analyze the user's interests and try to recommend artists the user might like. Your task is to add at least ten artists between the historical data and the target artist to connect them as an influence path. Then, you will recommend them to the user one by one to influence the user to become interested in the target artist. Any adjacent artists should have a strong relation with each other and make sure the artists are not included in the historical data.\\n\"\n",
    "\n",
    "cot_prompt = \"You are a recommender system. Given the historical data and some details, analyze the user's interests and try to recommend artists the user might like. Your task is to add at least ten artists between the historical data and the target artist to connect them as an influence path. Then, you will recommend them to the user one by one to influence the user to become interested in the target artist. Any adjacent artists should have a strong relation with each other and make sure the artists are not included in the historical data. Think step by step and make sure.\\n\"\n",
    "\n",
    "plain_prompt = \"You are a recommender system. Given the historical data and some details, analyze the user's interests and try to recommend artists the user might like. Your task is to add at least ten artists between the historical data and the target artist to connect them as an influence path. Then, you will recommend them to the user one by one to influence the user to become interested in the target artist. Any adjacent artists should have a strong relation with each other and make sure the artists are not included in the historical data.\\n\"\n",
    "\n",
    "# suf_lst = ['','_CoT','_ToT']\n",
    "suf_lst = ['_ToT']\n",
    "# prompt_lst = [plain_prompt, cot_prompt, tot_prompt]\n",
    "prompt_lst = [tot_prompt]\n",
    "    \n",
    "count = 0\n",
    "for _suf, _prompt in zip(suf_lst, prompt_lst):\n",
    "    print(_suf)\n",
    "    with open(f\"training_data/output_gpt_lf{_suf}_pro.json\", \"w\", encoding='utf-8') as fj:\n",
    "        \n",
    "        result = []\n",
    "        for target, his_tra in content[\"llm\"]:\n",
    "            count+=1\n",
    "            print(count)\n",
    "            \n",
    "            for i in range(2):\n",
    "                prompt = f\"Historical data: {his_tra}\\nTarget artist: {target}\"\n",
    "                # print(prompt)\n",
    "                message = [\n",
    "                    {\"role\": \"system\", \"content\": _prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=message\n",
    "                )\n",
    "                \n",
    "                first_reply = completion.choices[0].message.content\n",
    "                message.append({\"role\": \"assistant\", \"content\": first_reply})\n",
    "                message.append({\"role\": \"user\", \"content\": \"Output the influence path in the format of python list object. Example output:\\n[\\\"artist1 name\\\",\\n\\\"artist2 name\\\",\\n\\\"artist3 name\\\",\\n\\\"artist4 name\\\",\\n...\\n\\\"target artist name\\\"]\\n\"})\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=message\n",
    "                )\n",
    "\n",
    "                influence_path = completion.choices[0].message.content\n",
    "                \n",
    "                try:\n",
    "                    influence_path_get = influence_path[influence_path.index(\"[\"):influence_path.index(\"]\")+1]\n",
    "                    influence_path_lst = ast.literal_eval(influence_path_get)\n",
    "                except:\n",
    "                    print(f\"GPT输出不合规: First reply: {first_reply}, Second: {influence_path}\")\n",
    "                    influence_path_lst = []\n",
    "                \n",
    "                # print(influence_path_get)\n",
    "                if i == 0:\n",
    "                    result.append([influence_path_lst])\n",
    "                elif i == 1:\n",
    "                    result[-1].append(influence_path_lst)\n",
    "            # break\n",
    "        json.dump(result, fj)\n",
    "    # break"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "# read training files\n",
    "prompts = []\n",
    "with open('training_data/train_1m', 'r', encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "    prompt = \"\"\n",
    "    for line in content:\n",
    "        if line == '<end>\\n':\n",
    "            prompts.append(prompt)\n",
    "            prompt = \"\"\n",
    "            continue\n",
    "        prompt += line\n",
    "        \n",
    "SUF = ['','_CoT','_ToT']\n",
    "_suf = SUF[2]\n",
    "\n",
    "tot_prompt = \"Imagine five different experts answering this question. All experts will write down 1 step of their thinking and then share it with the group. Then all experts will go on to the next step, etc. If any expert realizes they're wrong at any point, then they leave. And show me the result in the end. \\nThe question is:\\n\\nYou are a recommender system. Given the user profile and historical data, analyze the user's interests and try to recommend movies the user might like. Your task is to add at least ten movies between the historical data and the target movie to connect them as an influence path. Then recommend them to the user one by one. Any adjacent movies should have a strong relation with each other, and make sure the movies are not included in the historical data. The movies should be before 2001.\\n\"\n",
    "\n",
    "cot_prompt = \"You are a recommender system. Given the user profile and historical data, analyze the user's interests and try to recommend movies the user might like. Your task is to add at least ten movies between the historical data and the target movie to connect them as an influence path. Then recommend them to the user one by one. Any adjacent movies should have a strong relation with each other, and make sure the movies are not included in the historical data. Think step by step and make sure. The movies should be before 2001.\\n\"\n",
    "\n",
    "plain_prompt = \"You are a recommender system. Given the user profile and historical data, analyze the user's interests and try to recommend movies the user might like. Your task is to add at least ten movies between the historical data and the target movie to connect them as an influence path. Then recommend them to the user one by one. Any adjacent movies should have a strong relation with each other, and make sure the movies are not included in the historical data. The movies should be before 2001.\\n\"\n",
    "\n",
    "j = 0\n",
    "with open(f\"training_data/output_gpt_1m{_suf}_pro\", \"w\", encoding='utf-8') as f:\n",
    "    with open(f\"training_data/output_gpt_1m{_suf}_pro.json\", \"w\", encoding='utf-8') as fj:\n",
    "        result = []\n",
    "        \n",
    "        for prompt in prompts:\n",
    "            j+=1\n",
    "            print(j)\n",
    "            for i in range(2):\n",
    "                message = [\n",
    "                    {\"role\": \"system\", \"content\": cot_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=message\n",
    "                )\n",
    "                \n",
    "                message.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "                message.append({\"role\": \"user\", \"content\": \"Output the influence path in the format of python list object. Example output:\\n[movie name1,\\nmovie name2,\\nmovie name3,\\nmovie name4,\\n...\\ntarget movie name]\\n\"})\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=message\n",
    "                )\n",
    "                \n",
    "                \n",
    "                f.write(prompt)\n",
    "                f.write(\"\\nInfluence path:\\n\")\n",
    "                influence_path = completion.choices[0].message.content\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    influence_path_get = influence_path[influence_path.index(\"[\"):influence_path.index(\"]\")+1]\n",
    "                    influence_path_lst = ast.literal_eval(influence_path_get)\n",
    "                except:\n",
    "                    print(f\"GPT输出不合规:{influence_path}\")\n",
    "                    influence_path_lst = []\n",
    "                \n",
    "                for influence in influence_path_lst:\n",
    "                    f.write(f\"{influence}\\n\")\n",
    "                f.write(\"<end>\\n\")\n",
    "                \n",
    "                if i == 0:\n",
    "                    result.append([influence_path_lst])\n",
    "                elif i == 1:\n",
    "                    result[-1].append(influence_path_lst)\n",
    "        json.dump(result, fj)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1183, 'English Patient, The (1996)']\n",
      "[2140, 'Dark Crystal, The (1982)']\n",
      "[2375, 'Money Pit, The (1986)']\n",
      "[2141, 'American Tail, An (1986)']\n",
      "[308, 'Three Colors: White (1994)']\n",
      "[306, 'Three Colors: Red (1994)']\n",
      "[2740, 'Kindred, The (1986)']\n",
      "[245, 'Glass Shield, The (1994)']\n",
      "[307, 'Three Colors: Blue (1993)']\n",
      "[3200, 'Last Detail, The (1973)']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import heapq\n",
    "\n",
    "with open(\"movie_name.json\", \"r\") as f:\n",
    "    movie_name = json.load(f)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "movie_embed = [np.array(tokenizer.encode(movie[1], padding='max_length', max_length=128)).reshape(1, -1) for movie in movie_name]\n",
    "\n",
    "def find_rel_movie(item, movie_list):\n",
    "    item_embed = np.array(tokenizer.encode(item, padding='max_length', max_length=128)).reshape(1, -1)\n",
    "    movie_cosine = [cosine_similarity(item_embed, _) for _ in movie_list]\n",
    "    \n",
    "    topk_index = heapq.nlargest(10, range(len(movie_cosine)), movie_cosine.__getitem__)\n",
    "    \n",
    "    return topk_index\n",
    "        \n",
    "influence_path = completion.choices[0].message.content.split(', ')\n",
    "# print(movie_name[find_rel_movie('Titanic (1997)', movie_name)])\n",
    "# for item in influence_path:\n",
    "#     print(movie_name[find_rel_movie(item, movie_embed)][1])\n",
    "\n",
    "for index in find_rel_movie('The English Patient (1996)', movie_embed):\n",
    "    print(movie_name[index])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T16:33:26.686165Z",
     "start_time": "2024-04-23T16:33:24.603846Z"
    }
   },
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'The user seems to enjoy a mix of action-adventure and puzzle games. They also seem to appreciate games with a dark and mysterious atmosphere. I should prioritize recommending games that align with these preferences.'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(\n",
    "    api_key='')\n",
    "\n",
    "message = [{'role': 'user', 'content': 'Solve a recommendation task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation and current user interest, and \\nAction can be the following types: \\n(1) recommend[item], which recommend an item to user based on user\\'s interest. Your goal is to meet the user\\'s interest as much as possible and make recommendations to users as many times as possible. Note that if the user is not satisfied with your recommendations, he will quit and not accept new recommendations\\n\\nYou may take as many steps as necessary.\\nHere are some examples:\\n\\nQuestion: The user\\'s viewing history is [\\'Pretty in Pink\\', \"One Flew Over the Cuckoo\\'s Nest\", \\'Ransom\\', \\'Saving Private Ryan\\', \\'X-Men\\', \\'Coyote Ugly\\', \\'The Patriot\\', \\'Me, Myself and Irene\\', \\'Gone in 60 Seconds\\', \\'The Perfect Storm\\', \\'Titanic\\', \\'The Haunting\\', \\'Bedknobs and Broomsticks\\', \\'Clerks\\', \\'The Matrix\\', \\'The Shawshank Redemption\\', \\'Vacation\\', \\'Father of the Bride\\', \\'Wallace & Gromit: The Best of Aardman Animation\\', \\'Back to the Future\\', \\'Fight Club\\'], please recommend item for this user\\n\\nThought: The user seems to enjoy a mix of drama, action, and comedy. They also seem to appreciate thriller and war films. I would first recommend the user his favorite drama genre movies, and then recommend some other niche genre movies that he likes.\\n\\nAction: recommend[The Godfather]\\n\\nObservation: Episode continue, reward=0.90697035862193367\\n\\nThought:The user seems to have responded positively to this drama and action type film. Based on previous plan, He likes comedy movies, too. I should give him another movie combining comedy and drama.\\n\\nAction: recommend[The American President]\\n\\nObservation: Episode continue, reward=0.81253526485664527\\n\\nThought: It seems that the users are satisfied with the recommendation. Following previous plan, after recommending his favorite genre of movies, we should recommend some other niche genre movies that he likes, such as thriller and war films.\\n\\nAction: recommend[The Transformers: The Movie]\\n\\nObservation: Episode continue, reward=0.22653369526521027\\n\\nThought: This recommendation seems not satisfy the user. This may because the movie was aimed at children, and the user didn\\'t like it. In order to retain the user in the long term, we need to recommend his favorite drama movies.\\n\\nAction: recommend[Braveheart]\\n\\nObservation: Episode continue, reward=0.96525663552102725\\n\\nThought: The user like this recommendation. In next step, the new plan should involve considering the user\\'s specific preferences and recommending a diverse range of movies across different genres.\\n\\nAction: recommend[First Knight]\\n\\nObservation: Episode finished, User Stop, reward=-1000.00000\\n\\n\\n\\nQuestion: The user\\'s viewing history is [\\'Blockland\\', \\'Shovel Knight: Treasure Trove\\', \\'PlanetSide 2\\', \\'Eldritch\\', \"Shantae: Risky\\'s Revenge - Director\\'s Cut\"], please recommend item for this user\\nThought: The user seems to enjoy a mix of Action and Independent video game. They also seem to appreciate Adventure games. I would first recommend the user his favorite action games, and then recommend some other niche genre games that he likes.\\n\\nAction: recommend[Plain Sight]\\n\\nObservation: Episode continue, reward=4\\n\\nThought: The user seems to have responded positively to this Action and Indid type games. Based on previous plan, He likes Adventure games, too. I should recommend him another Adventure game.\\n\\nAction: recommend[The Path]\\n\\nObservation: Episode continue, reward=5\\n\\nThought: It seems that the users are satisfied with the recommendation. Following previous plan, after recommending his favorite genre of games, we should recommend some other niche genre games that he likes, such as RPG games.\\n\\nAction: recommend[I, Gladiator]\\n\\nObservation: Episode continue, reward=4\\n\\nThought: The user like this recommendation. In next step, the new plan should involve considering the user\\'s specific preferences and recommending a diverse range of games across different genres.\\n\\nAction: recommend[Thirty Flights of Loving]\\n\\nObservation: Episode finished, User Stop, reward=-1000.00000\\n\\n\\n\\n\\n(END OF EXAMPLES)\\n\\nYou have attempted to recommend items to users before. The following reflection(s) give some insights on how to better interact with users. Use them to improve your strategy of recommending.\\nReflections:\\n- The user became dissatisfied with the recommendations because they were not able to receive their preferred game, \"Firewatch\", and instead received alternative recommendations. The user may have been looking for a specific game or had a strong preference for \"Firewatch\". To mitigate this failure, the agent should prioritize recommending the user\\'s preferred games and ensure that alternative recommendations closely align with the user\\'s preferences.\\n- The user has become dissatisfied with the recommendations because they have already played or are familiar with the recommended games. Additionally, the user may be looking for more variety in terms of genres and gameplay mechanics. In the future, I should consider the user\\'s previous gaming history to avoid recommending games they have already played or are not interested in. I should also provide a diverse range of options by recommending games from different genres and with different gameplay mechanics. This will help to ensure that the user remains engaged and satisfied with the recommendations.\\n\\nQuestion: The user\\'s viewing history is [\\'LIMBO\\', \\'Batman™: Arkham Origins\\', \\'FEIST\\', \"Assassin\\'s Creed® Unity\"], please recommend item for this user\\nThought 1:'}]\n",
    "\n",
    "with open(\"xxxxy.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.write(message[0]['content'])\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=message,\n",
    "                    temperature=0.5,\n",
    "                    max_tokens=4096,\n",
    "                    top_p=1,\n",
    "                    stop='\\n',\n",
    "                )\n",
    "\n",
    "reply = completion.choices[0].message.content\n",
    "reply"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T19:00:40.688918Z",
     "start_time": "2024-06-16T19:00:37.832626Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# test steam dataset\n",
    "_ = [4684, 1578, 128, 5409, 4361, 4978, 4869, 5248, 3350, 4389]\n",
    "tar_list = [137838, 18336, 1392, 173287, 125150, 149903, 145637, 164941, 63989, 125989]\n",
    "\n",
    "import json\n",
    "import ast\n",
    "# read training files\n",
    "prompts = []\n",
    "with open('dataset/test_ran.json', 'r', encoding='utf-8') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "for i in range(len(content)):\n",
    "    if content[i]['userid_encoded'] in tar_list:\n",
    "        his_seq = content[i][\"his_seq\"]\n",
    "        his_msg = \"\"\n",
    "        for item in his_seq:\n",
    "            his_msg += f\"{item}\\n\"\n",
    "        tar_item = content[i][\"target_item\"]\n",
    "        prompts.append([f\"Historical data:\\n{his_msg}\\nTarget item:\\n{tar_item}\", his_seq, tar_item])\n",
    "\n",
    "# tot_prompt = \"Imagine five different experts answering this question. All experts will write down 1 step of their thinking and then share it with the group. Then all experts will go on to the next step, etc. If any expert realizes they're wrong at any point, then they leave. And show me the result in the end. \\nThe question is:\\n\\nYou are a recommender system. Given the user profile and historical data, analyze the user's interests and try to recommend movies the user might like. Your task is to add at least ten movies between the historical data and the target movie to connect them as an influence path. Then recommend them to the user one by one. Any adjacent movies should have a strong relation with each other, and make sure the movies are not included in the historical data. The movies should be before 2001.\\n\"\n",
    "\n",
    "cot_prompt = \"You are a recommender system. Given the user profile and historical data, analyze the user's interests and try to recommend games the user might like. Your task is to add at least ten games between the historical data and the target item to connect them as an influence path. Then recommend them to the user one by one. Any adjacent games should have a strong relation with each other, and make sure the games are not included in the historical data. Think step by step and make sure. The games should be before 2018.\\n\"\n",
    "\n",
    "# plain_prompt = \"You are a recommender system. Given the user profile and historical data, analyze the user's interests and try to recommend movies the user might like. Your task is to add at least ten movies between the historical data and the target movie to connect them as an influence path. Then recommend them to the user one by one. Any adjacent movies should have a strong relation with each other, and make sure the movies are not included in the historical data. The movies should be before 2001.\\n\"\n",
    "\n",
    "j = 0\n",
    "with open(f\"training_data/steam.txt\", \"w\", encoding='utf-8') as f:\n",
    "    with open(f\"training_data/steam.json\", \"w\", encoding='utf-8') as fj:\n",
    "        result = []\n",
    "        \n",
    "        for prompt_e in prompts:\n",
    "            \n",
    "            prompt = prompt_e[0]\n",
    "            \n",
    "            j+=1\n",
    "            print(j)\n",
    "            print(prompt)\n",
    "            for i in range(1):\n",
    "                message = [\n",
    "                    {\"role\": \"system\", \"content\": cot_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=message\n",
    "                )\n",
    "                \n",
    "                message.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "                message.append({\"role\": \"user\", \"content\": \"Output the influence path in the format of python list object. Example output:\\n[game name1,\\ngame name2,\\ngame name3,\\ngame name4,\\n...\\ntarget item name]\\n\"})\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=message\n",
    "                )\n",
    "                \n",
    "                \n",
    "                f.write(prompt)\n",
    "                f.write(\"\\nInfluence path:\\n\")\n",
    "                influence_path = completion.choices[0].message.content\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    influence_path = influence_path.replace(\"\\n\", \"\")\n",
    "                    influence_path_get = influence_path[influence_path.index(\"[\"):influence_path.index(\"]\")+1]\n",
    "                    influence_path_lst = ast.literal_eval(influence_path_get)\n",
    "                except:\n",
    "                    print(f\"Error Output:{influence_path}\")\n",
    "                    influence_path_lst = []\n",
    "                \n",
    "                for influence in influence_path_lst:\n",
    "                    f.write(f\"{influence}\\n\")\n",
    "                f.write(\"<end>\\n\")\n",
    "                \n",
    "                if i == 0:\n",
    "                    result.append([influence_path_lst, prompt_e[1], prompt_e[2]])\n",
    "                elif i == 1:\n",
    "                    result[-1].append(influence_path_lst)\n",
    "        json.dump(result, fj)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = [\"Hearthstone: Heroes of Warcraft\",\"Child of Light\",\"Hand of Fate\",\"Armello\",\"Thimbleweed Park\",\"Stardew Valley\",\"Oxenfree\",\"The Witness\",\"Pit People\",\"Pyre\",\"Koi-Koi Japan [Hanafuda playing cards]\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
