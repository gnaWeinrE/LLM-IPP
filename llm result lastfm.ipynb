{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json \n",
    "import re\n",
    "\n",
    "path = \"training_data/lastfm\"\n",
    "# suffix_list = ['', '_CoT', '_ToT', '_IRSfix', '_IRSori', '_POP', '_random']\n",
    "# _suf = suffix_list[5]\n",
    "suffix_list = ['_IRSfix', '_IRSori', '_POP']\n",
    " \n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=''\n",
    ")\n",
    "\n",
    "prompt_system_accept = \"You are a recommender system. Given the user profile and historical data, analyze the user's interests. Based on this information, would the user be interested in the music artists in the Influence path step by step? Answer with a probability for an artist between 0 and 1, where 0 means 'definitely not interested' and 1 means 'definitely interested'. If uncertain, make your best guess, then return the mean probability.\"\n",
    "\n",
    "prompt_system_relevance = \"You are a professional music critic. Given the Influence path, based on your understanding of the music artists, what's the relatedness of each 2 adjacent artists in the influence path? Answer with a probability between 0 and 1, where 1 means 'definitely related' and 0 means 'definitely not related'. If uncertain, make your best guess, then return the mean probability.\"\n",
    "\n",
    "# prompt_list = [prompt_system_accept, prompt_system_relevance]\n",
    "# prompt_suf = ['_accept', '_rel']\n",
    "\n",
    "system_prompt_list = [[prompt_system_accept, '_accept'], [prompt_system_relevance, '_rel']]\n",
    "\n",
    "def get_score(_question, _prompt, _system):\n",
    "    # influence_path = get_movies(_question)\n",
    "    \n",
    "    if _prompt == []:\n",
    "        return [0,0]\n",
    "    else:\n",
    "        influence_path = str.join(\"\\n\", _prompt)\n",
    "\n",
    "    user_prompt = f\"Historical data:\\n{_question}\\nInfluence path:\\n{influence_path}\"\n",
    "    \n",
    "    # print(user_prompt)\n",
    "    \n",
    "    \n",
    "    loop_flag = 0\n",
    "    while True:\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": _system},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "                messages=message\n",
    "            )\n",
    "        # print(completion.choices[0].finish_reason)\n",
    "        message.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "        message.append({\"role\": \"user\", \"content\": \"Only numerical response required, without any other word. Output the mean probability.\"})\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=message\n",
    "        )\n",
    "        \n",
    "        gpt_reply = completion.choices[0].message.content\n",
    "        # print(gpt_reply)\n",
    "        # print(gpt_reply)\n",
    "        # print(mean_pro)\n",
    "        if re.search('0\\.\\d+', gpt_reply):\n",
    "            return [float(re.search('0\\.\\d+', gpt_reply).group()), gpt_reply]\n",
    "        \n",
    "        loop_flag += 1\n",
    "        if loop_flag >= 2:\n",
    "            print(gpt_reply)\n",
    "            \n",
    "for _prompt, _system_suf in system_prompt_list:\n",
    "    print(_system_suf)\n",
    "    for _suf in suffix_list:\n",
    "        with open(f\"training_data/lastfm/output_gpt_lf{_suf}_pro.json\", \"r\", encoding='utf-8') as f:\n",
    "            path_result = json.load(f)\n",
    "        with open(\"training_data/train_lf.json\", \"r\", encoding='utf-8') as f:\n",
    "            training_data_prompt = json.load(f)\n",
    "    \n",
    "        k = 1\n",
    "        all_result = []\n",
    "        for his_tra, influ_path in zip(training_data_prompt['llm'], path_result):\n",
    "            # if(k%20==0):\n",
    "            #     print(k)\n",
    "            print(k)\n",
    "            k+=1\n",
    "            all_result.append([get_score(his_tra[1], influ_path[0], _prompt),get_score(his_tra[1], influ_path[1], _prompt)])\n",
    "            # print(all_result)\n",
    "            # break\n",
    "            if k == 20:\n",
    "                break\n",
    "        \n",
    "        with open(f\"training_data/lastfm/llm_result_{_suf}{_system_suf}_GPT3.json\", \"w\") as outfile:\n",
    "            json.dump(all_result, outfile)\n",
    "        sum = 0\n",
    "        count = 0\n",
    "        \n",
    "        for _ in all_result:\n",
    "            a = _[0][0]\n",
    "            b = _[1][0]\n",
    "            max_ = max(a, b)\n",
    "            if max_ == 0:\n",
    "                continue\n",
    "            sum += max_\n",
    "            count += 1\n",
    "        \n",
    "        print(_suf)\n",
    "        print(sum/count)"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
