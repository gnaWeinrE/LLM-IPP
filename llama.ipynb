{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-09T15:54:11.375940Z",
     "start_time": "2024-08-09T15:54:06.506219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'model': 'llama3',\n 'created_at': '2024-08-09T15:54:11.3689119Z',\n 'message': {'role': 'assistant',\n  'content': 'Meowwwww! *rubs against leg* Hi there, friend! How can I help or entertain you today?'},\n 'done_reason': 'stop',\n 'done': True,\n 'total_duration': 2826758300,\n 'load_duration': 2445932900,\n 'prompt_eval_count': 13,\n 'prompt_eval_duration': 19859000,\n 'eval_count': 26,\n 'eval_duration': 359662000}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"llama3\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hello, kitty\"}\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"options\": {\n",
    "        \"temperature\": 0.7,\n",
    "        \"num_predict\": -1,\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"Meow! *rubs against leg* Ah, nice to meet you human. I'm feeling quite purr-fect today. The sunbeams in this room are simply divine. *stretches and arches back* Do you have some treats for me?\""
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['message']['content']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-09T15:53:29.446030Z",
     "start_time": "2024-08-09T15:53:29.433004Z"
    }
   },
   "id": "100e91ff60db0de8",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_accept\n",
      "_IRSfix\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "124\n",
      "0.5804182044715392\n",
      "_IRSori\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "124\n",
      "0.5974048779945528\n",
      "_POP\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "124\n",
      "0.591758672059621\n",
      "_rel\n",
      "_IRSfix\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "124\n",
      "0.47546549167669355\n",
      "_IRSori\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "124\n",
      "0.45836712708601396\n",
      "_POP\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "124\n",
      "0.45371633054843014\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "path = \"training_data/pro\"\n",
    "# suffix_list = ['', '_CoT', '_ToT']\n",
    "suffix_list = ['_IRSfix', '_IRSori', '_POP']\n",
    "# _suf = suffix_list[0]\n",
    "_model_suf = '_llama3'\n",
    "model_name = 'llama3'\n",
    "\n",
    "prompt_system_accept = \"You are a recommender system. Given the user profile and historical data, analyze the user's interests. Based on this information, would the user be interested in watching the movies in the Influence path step by step? Answer with a probability for a movie between 0 and 1, where 0 means 'definitely not interested' and 1 means 'definitely interested'. If uncertain, make your best guess, then return the mean probability.\"\n",
    "\n",
    "prompt_system_relevance = \"You are a professional movie critic. Given the Influence path, based on your understanding of the movies, what's the relatedness of each 2 adjacent movies in the influence path? Answer with a probability between 0 and 1, where 1 means 'definitely related' and 0 means 'definitely not related'. If uncertain, make your best guess, then return the mean probability.\"\n",
    "\n",
    "system_prompt_list = [[prompt_system_accept, '_accept'], [prompt_system_relevance, '_rel']]\n",
    "\n",
    "def get_score(_question, _prompt, _system_prompt):\n",
    "    if _prompt == []:\n",
    "        return [0, 0]\n",
    "    else:\n",
    "        influence_path = str.join(\"\\n\", _prompt)\n",
    "\n",
    "    _question = _question[:_question.index(\"Target movie:\")]\n",
    "    user_prompt = f\"{_question}Influence path:\\n{influence_path}\"\n",
    "\n",
    "    # print(user_prompt)\n",
    "\n",
    "    loop_flag = 0\n",
    "    while True:\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": _system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "        data = {\n",
    "            \"model\": model_name,\n",
    "            \"messages\": message,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        response = requests.post(url, json=data)\n",
    "        # print(prompt_system_accept)\n",
    "        # print(user_prompt)\n",
    "        # print(response.text)\n",
    "        \n",
    "        # gpt_reply = response.json()['message']['content']\n",
    "        # print(gpt_reply)\n",
    "        try:\n",
    "            gpt_reply = response.json()['message']['content']\n",
    "        except:\n",
    "            print(f\"message: {user_prompt}\")\n",
    "            print(f\"Error: {response}\")\n",
    "            continue\n",
    "\n",
    "        message.append({\"role\": \"assistant\", \"content\": gpt_reply})\n",
    "        message.append({\"role\": \"user\", \"content\": \"Only numerical response required, without any other word. Output the mean probability.\"})\n",
    "        \n",
    "        data = {\n",
    "            \"model\": model_name,\n",
    "            \"messages\": message,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        response = requests.post(url, json=data)\n",
    "        \n",
    "        # gpt_reply = response.json()['message']['content']\n",
    "        # print(gpt_reply)\n",
    "        try:\n",
    "            gpt_reply = response.json()['message']['content']\n",
    "        except:\n",
    "            print(f\"message: {user_prompt}\")\n",
    "            print(f\"Error: {response}\")\n",
    "            continue\n",
    "        # print(gpt_reply)\n",
    "\n",
    "        if re.search('0\\.\\d+', gpt_reply):\n",
    "            return [float(re.search('0\\.\\d+', gpt_reply).group()), gpt_reply]\n",
    "\n",
    "        loop_flag += 1\n",
    "        if loop_flag >= 2:\n",
    "            print(gpt_reply)\n",
    "\n",
    "for system_prompt, system_prompt_suffix in system_prompt_list:\n",
    "    print(system_prompt_suffix)\n",
    "    for _suf in suffix_list:\n",
    "        print(_suf)\n",
    "        with open(f\"{path}/output_gpt_1m{_suf}_pro.json\", \"r\", encoding='utf-8') as f:\n",
    "            path_result = json.load(f)\n",
    "        with open(\"training_data/train_1m.json\", \"r\", encoding='utf-8') as f:\n",
    "            training_data_prompt = json.load(f)\n",
    "        \n",
    "        k = 1\n",
    "        print(k)\n",
    "        all_result = []\n",
    "        for prefix, influ_path in zip(training_data_prompt['llm'], path_result):\n",
    "            if k % 20 == 0:\n",
    "                print(k)\n",
    "            k += 1\n",
    "            all_result.append([get_score(prefix[1], influ_path[0], system_prompt), get_score(prefix[1], influ_path[1], system_prompt)])\n",
    "            # print(all_result)\n",
    "            # if k == 20:\n",
    "            #     break\n",
    "            # break\n",
    "        print(k)\n",
    "        \n",
    "        with open(f\"{path}/llm_result_1m{_suf}{system_prompt_suffix}{_model_suf}.json\", \"w\") as outfile:\n",
    "            json.dump(all_result, outfile)\n",
    "        \n",
    "        sum = 0\n",
    "        count = 0\n",
    "        for _ in all_result:\n",
    "        \n",
    "            a = _[0][0]\n",
    "            b = _[1][0]\n",
    "            max_ = max(a, b)\n",
    "            if max_ == 0:\n",
    "                continue\n",
    "            sum += max_\n",
    "            count += 1\n",
    "        \n",
    "        print(sum / count)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T21:45:35.859221Z",
     "start_time": "2024-05-10T18:08:16.713248Z"
    }
   },
   "id": "606a8ae26911d5a3",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_accept\n",
      "\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.660361111111111\n",
      "_CoT\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.6723650332999996\n",
      "_ToT\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.6521161616161615\n",
      "_IRSfix\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.5245683333333333\n",
      "_IRSori\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.5250613333000002\n",
      "_POP\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.5213343333000002\n",
      "_rel\n",
      "\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.6679797979797979\n",
      "_CoT\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.6705203333333334\n",
      "_ToT\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.6574242424242424\n",
      "_IRSfix\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.42959458333333345\n",
      "_IRSori\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.4370898817285985\n",
      "_POP\n",
      "1\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "101\n",
      "0.4564230080608774\n"
     ]
    }
   ],
   "source": [
    "# Lastfm\n",
    "\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "path = \"training_data/lastfm\"\n",
    "# suffix_list = ['', '_CoT', '_ToT']\n",
    "suffix_list = ['', '_CoT', '_ToT', '_IRSfix', '_IRSori', '_POP']\n",
    "# _suf = suffix_list[0]\n",
    "_model_suf = '_llama3'\n",
    "model_name = 'llama3'\n",
    "\n",
    "prompt_system_accept = \"You are a recommender system. Given the user profile and historical data, analyze the user's interests. Based on this information, would the user be interested in the music artists in the Influence path step by step? Answer with a probability for an artist between 0 and 1, where 0 means 'definitely not interested' and 1 means 'definitely interested'. If uncertain, make your best guess, then return the mean probability.\"\n",
    "\n",
    "prompt_system_relevance = \"You are a professional music critic. Given the Influence path, based on your understanding of the music artists, what's the relatedness of each 2 adjacent artists in the influence path? Answer with a probability between 0 and 1, where 1 means 'definitely related' and 0 means 'definitely not related'. If uncertain, make your best guess, then return the mean probability.\"\n",
    "\n",
    "system_prompt_list = [[prompt_system_accept, '_accept'], [prompt_system_relevance, '_rel']]\n",
    "\n",
    "def get_score(_question, _prompt, _system_prompt):\n",
    "    if _prompt == []:\n",
    "        return [0, 0]\n",
    "    else:\n",
    "        influence_path = str.join(\"\\n\", _prompt)\n",
    "\n",
    "    # _question = _question[:_question.index(\"Target artist:\")]\n",
    "    # user_prompt = f\"{_question}Influence path:\\n{influence_path}\"\n",
    "    \n",
    "    user_prompt = f\"Historical data:\\n{_question}\\nInfluence path:\\n{influence_path}\"\n",
    "    \n",
    "    # print(user_prompt)\n",
    "\n",
    "    loop_flag = 0\n",
    "    while True:\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": _system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "        data = {\n",
    "            \"model\": model_name,\n",
    "            \"messages\": message,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        response = requests.post(url, json=data)\n",
    "        # print(prompt_system_accept)\n",
    "        # print(user_prompt)\n",
    "        # print(response.text)\n",
    "        \n",
    "        # gpt_reply = response.json()['message']['content']\n",
    "        # print(gpt_reply)\n",
    "        try:\n",
    "            gpt_reply = response.json()['message']['content']\n",
    "        except:\n",
    "            print(f\"message: {user_prompt}\")\n",
    "            print(f\"Error: {response}\")\n",
    "            continue\n",
    "\n",
    "        message.append({\"role\": \"assistant\", \"content\": gpt_reply})\n",
    "        message.append({\"role\": \"user\", \"content\": \"Only numerical response required, without any other word. Output the mean probability.\"})\n",
    "        \n",
    "        data = {\n",
    "            \"model\": model_name,\n",
    "            \"messages\": message,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        response = requests.post(url, json=data)\n",
    "        \n",
    "        # gpt_reply = response.json()['message']['content']\n",
    "        # print(gpt_reply)\n",
    "        try:\n",
    "            gpt_reply = response.json()['message']['content']\n",
    "        except:\n",
    "            print(f\"message: {user_prompt}\")\n",
    "            print(f\"Error: {response}\")\n",
    "            continue\n",
    "        # print(gpt_reply)\n",
    "\n",
    "        if re.search('0\\.\\d+', gpt_reply):\n",
    "            return [float(re.search('0\\.\\d+', gpt_reply).group()), gpt_reply]\n",
    "\n",
    "        loop_flag += 1\n",
    "        if loop_flag >= 2:\n",
    "            print(gpt_reply)\n",
    "\n",
    "for system_prompt, system_prompt_suffix in system_prompt_list:\n",
    "    print(system_prompt_suffix)\n",
    "    for _suf in suffix_list:\n",
    "        print(_suf)\n",
    "        with open(f\"{path}/output_gpt_lf{_suf}_pro.json\", \"r\", encoding='utf-8') as f:\n",
    "            path_result = json.load(f)\n",
    "        with open(\"training_data/train_lf.json\", \"r\", encoding='utf-8') as f:\n",
    "            training_data_prompt = json.load(f)\n",
    "        \n",
    "        k = 1\n",
    "        print(k)\n",
    "        all_result = []\n",
    "        for prefix, influ_path in zip(training_data_prompt['llm'], path_result):\n",
    "            if k % 20 == 0:\n",
    "                print(k)\n",
    "            k += 1\n",
    "            all_result.append([get_score(prefix[1], influ_path[0], system_prompt), get_score(prefix[1], influ_path[1], system_prompt)])\n",
    "            # print(all_result)\n",
    "            # if k == 20:\n",
    "            #     break\n",
    "            # break\n",
    "        print(k)\n",
    "        \n",
    "        with open(f\"{path}/llm_result_lf{_suf}{system_prompt_suffix}{_model_suf}.json\", \"w\") as outfile:\n",
    "            json.dump(all_result, outfile)\n",
    "        \n",
    "        sum = 0\n",
    "        count = 0\n",
    "        for _ in all_result:\n",
    "        \n",
    "            a = _[0][0]\n",
    "            b = _[1][0]\n",
    "            max_ = max(a, b)\n",
    "            if max_ == 0:\n",
    "                continue\n",
    "            sum += max_\n",
    "            count += 1\n",
    "        \n",
    "        print(sum / count)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T23:44:26.772522Z",
     "start_time": "2024-05-15T17:37:46.196323Z"
    }
   },
   "id": "78bfbdfb91ba27fc",
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
