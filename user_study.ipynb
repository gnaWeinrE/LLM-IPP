{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb19f9d36bde984",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T05:07:04.706239Z",
     "start_time": "2024-10-01T05:07:03.117215Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(\n",
    "    api_key=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 生成回答\n",
    "import json\n",
    "import ast\n",
    "# read training files\n",
    "with open('training_data/train_1m.json', 'r', encoding='utf-8') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "tot_prompt = \"Imagine five different experts answering this question. All experts will write down 1 step of their thinking and then share it with the group. Then all experts will go on to the next step, etc. If any expert realizes they're wrong at any point, then they leave. And show me the result in the end. \\nThe question is:\\n\\nYou are a recommender system. Given the user profile and historical data, analyze the user's interests and try to recommend movies the user might like. Your task is to add at least ten movies between the historical data and the target movie to connect them as an influence path. Then recommend them to the user one by one. Any adjacent movies should have a strong relation with each other, and make sure the movies are not included in the historical data. The movies should be before 2001.\\n\"\n",
    "\n",
    "cot_prompt = \"You are a recommender system. Given the user profile and historical data, analyze the user's interests and try to recommend movies the user might like. Your task is to add at least ten movies between the historical data and the target movie to connect them as an influence path. Then recommend them to the user one by one. Any adjacent movies should have a strong relation with each other, and make sure the movies are not included in the historical data. Think step by step and make sure, then tell the reason. The movies should be before 2001.\\n\"\n",
    "\n",
    "plain_prompt = \"You are a recommender system. Given the user profile and historical data, analyze the user's interests and try to recommend movies the user might like. Your task is to add at least ten movies between the historical data and the target movie to connect them as an influence path. Then recommend them to the user one by one. Any adjacent movies should have a strong relation with each other, and make sure the movies are not included in the historical data. The movies should be before 2001.\\n\"\n",
    "\n",
    "analysis_prompt = \"You are a user analyzer. Given the user profile and historical liked movies, analyze the user's interests.\"\n",
    "\n",
    "# suf_lst = ['','_CoT','_ToT']\n",
    "suf_lst = ['_COT']\n",
    "# prompt_lst = [plain_prompt, cot_prompt, tot_prompt]\n",
    "prompt_lst = [cot_prompt]\n",
    "\n",
    "count = 0\n",
    "for _suf, _prompt in zip(suf_lst, prompt_lst):\n",
    "    print(_suf)\n",
    "    \n",
    "    final_result = []\n",
    "    for target, his_tra in content[\"llm\"]:\n",
    "        count+=1\n",
    "        print(count)\n",
    "        \n",
    "        each_result = []\n",
    "        for i in range(2):\n",
    "            output = {}\n",
    "            prompt = f\"Historical data: {his_tra}\\nTarget movie: {target}\"\n",
    "            \n",
    "            message = [\n",
    "                {\"role\": \"system\", \"content\": _prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=message\n",
    "            )\n",
    "            \n",
    "            first_reply = completion.choices[0].message.content\n",
    "            message.append({\"role\": \"assistant\", \"content\": first_reply})\n",
    "            message.append({\"role\": \"user\", \"content\": \"Output the influence path in the format of python list object. Example output:\\n[movie name1,\\nmovie name2,\\nmovie name3,\\nmovie name4,\\n...\\ntarget movie name]\\n\"})\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=message\n",
    "            )\n",
    "            \n",
    "            influence_path = completion.choices[0].message.content\n",
    "            \n",
    "            try:\n",
    "                influence_path_get = influence_path[influence_path.index(\"[\"):influence_path.index(\"]\")+1]\n",
    "                influence_path_lst = ast.literal_eval(influence_path_get)\n",
    "            except:\n",
    "                print(f\"GPT输出不合规: First reply:\\n {first_reply}, Second:\\n {influence_path}\")\n",
    "                influence_path_lst = []\n",
    "            \n",
    "            each_result.append({'first': first_reply, 'second': influence_path, 'list': influence_path_lst})\n",
    "            \n",
    "        final_result.append(each_result)\n",
    "        with open(f\"user_study/examples.json\", \"w\", encoding='utf-8') as fj:\n",
    "            json.dump(final_result, fj)"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [07:00<00:00,  3.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# 生成解释\n",
    "import json\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "# read training files\n",
    "with open('training_data/train_1m.json', 'r', encoding='utf-8') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "analysis_prompt = \"You are a user analyzer. Given the user profile and historical liked movies, analyze the user's interests.\"\n",
    "\n",
    "final_result = []\n",
    "for target, his_tra in tqdm(content[\"llm\"]):\n",
    "    \n",
    "    each_result = []\n",
    "    output = {}\n",
    "    prompt = f\"Historical liked movies: {his_tra}\"\n",
    "    \n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": analysis_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=message\n",
    "    )\n",
    "    \n",
    "    first_reply = completion.choices[0].message.content\n",
    "    final_result.append({\"his_seq\": his_tra, \"target\": target, \"analysis\": first_reply})\n",
    "    \n",
    "    with open(f\"user_study/user_analysis.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(final_result, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T05:14:07.780144Z",
     "start_time": "2024-10-01T05:07:07.083012Z"
    }
   },
   "id": "e30679b753213a61",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "with open('user_study/movieLensTitles.json', 'r', encoding='utf-8') as f:\n",
    "    movie_titles = json.load(f)\n",
    "    \n",
    "with open('user_study/outputIRS.json', 'r', encoding='utf-8') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "final_result = []\n",
    "for path, _ in content:\n",
    "    final_list = [movie_titles[x] for x in path]\n",
    "    final_result.append({'list': path, 'final_list': final_list})\n",
    "\n",
    "with open(f\"user_study/outputIRSv2.json\", \"w\", encoding='utf-8') as fj:\n",
    "    json.dump(final_result, fj)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T19:08:59.921678Z",
     "start_time": "2024-09-24T19:08:59.904646Z"
    }
   },
   "id": "6d01c6a48b63b0e8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 生成问卷\n",
    "import json\n",
    "import random\n",
    "\n",
    "with open('user_study/output.json', 'r', encoding='utf-8') as f:\n",
    "    gpt_content = json.load(f)\n",
    "with open('user_study/outputIRSv2.json', 'r', encoding='utf-8') as f:\n",
    "    irs_content = json.load(f)\n",
    "\n",
    "def just_genre(seq):\n",
    "    movie_title_seq = [[_[:_.index(' Genre:')], _[_.index(' Genre:'):]] if ' Genre:' in _ else [_, '']for _ in seq]\n",
    "    offset = max([_[0] for _ in movie_title_seq], key=len, default=\"\")\n",
    "    return [_[0].ljust(len(offset)+5) + _[1] for _ in movie_title_seq]\n",
    "\n",
    "answer = []\n",
    "nn = 1\n",
    "with open('user_study/user_study.json', 'w', encoding='utf-8') as fi:\n",
    "    for [A, B], I in zip(gpt_content, irs_content):\n",
    "        gpt_pathA = just_genre(A['final_list'])\n",
    "        gpt_pathB = just_genre(B['final_list'])\n",
    "        irs_path = just_genre(I['final_list'][:-1])\n",
    "        \n",
    "        if len(gpt_pathA) > 5:\n",
    "            gpt_list = gpt_pathA\n",
    "        elif len(gpt_pathB) > 5:\n",
    "            gpt_list = gpt_pathB\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if len(irs_path) < 5:\n",
    "            continue\n",
    "        \n",
    "        gpt_list += (25-len(gpt_list)) * [\"\"]\n",
    "        gpt_list = gpt_list[:12]\n",
    "        \n",
    "        irs_path += (25-len(irs_path)) * [\"\"]\n",
    "        irs_path = irs_path[:12]\n",
    "        \n",
    "        \n",
    "        if len(I['final_list']) < 25:\n",
    "            fi.write('User:'+str(nn)+'\\n')\n",
    "            prompt_content = A['prompt'].replace('|', ',').split('\\n')\n",
    "            prompt_content = just_genre(prompt_content)\n",
    "            for line in prompt_content:\n",
    "                fi.write(line+'\\n')\n",
    "            fi.write(\"\\n\\n\")\n",
    "            # print(A['prompt'])\n",
    "            # print(\"\\n\\n\")\n",
    "    \n",
    "            x = random.choice([True,False])  # True 左边是gpt\n",
    "            answer.append(x)\n",
    "            if x:\n",
    "                offset = max(gpt_list, key=len, default=\"\")\n",
    "                for gpt_item, irs_item in zip(gpt_list, irs_path):\n",
    "                    irs_item = irs_item.replace(\"|\", \",\")\n",
    "                    fi.write(f'{gpt_item.ljust(len(offset)+5)} {irs_item}\\n')\n",
    "            else:\n",
    "                offset = max(irs_path, key=len, default=\"\")\n",
    "                for gpt_item, irs_item in zip(gpt_list, irs_path):\n",
    "                    irs_item = irs_item.replace(\"|\", \",\")\n",
    "                    fi.write(f'{irs_item.ljust(len(offset)+5)} {gpt_item}\\n')\n",
    "                    \n",
    "            fi.write(\"\\n\\n\\n\\n\")\n",
    "            # break\n",
    "        \n",
    "        # print(nn)\n",
    "        nn += 1\n",
    "\n",
    "with open('user_study/user_study_answer.json', 'w', encoding='utf-8') as fa:\n",
    "    json.dump(answer, fa)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T18:20:06.865050Z",
     "start_time": "2024-10-04T18:20:06.831004Z"
    }
   },
   "id": "e4fad23929a2c4cc",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.1\n",
      "0.6363636363636364\n",
      "0.26666666666666666\n",
      "0.8421052631578947\n",
      "0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "# 检查AB test user study 结果\n",
    "import json\n",
    "test_result_1 = 'abbaabbaab' + 'baaaabaacc' + 'abbcbabaaa'\n",
    "test_result_3 = 'bacbcbbcab' + 'cbabccccbb' + 'ababcabccb' + 'cbccbbccaa'\n",
    "test_result_2 = 'cabbccaaab' + 'bcababacab' + 'bacbcacaaa' + 'bbbabbbacc'\n",
    "\n",
    "# test_result = test_result_1\n",
    "\n",
    "with open('user_study/user_study_answer.json', 'r', encoding='utf-8') as fa:\n",
    "    answer = json.load(fa)\n",
    "    answer = ['a' if _ else 'b' for _ in answer]\n",
    "\n",
    "for test_result in [test_result_1, test_result_2, test_result_3]:\n",
    "    acc = []\n",
    "    unpredict = 0\n",
    "    for _ in range(30):\n",
    "        if test_result[_] == 'c':\n",
    "            unpredict += 1\n",
    "        elif test_result[_] == answer[_]:\n",
    "            acc.append(1)\n",
    "        else:\n",
    "            acc.append(0)\n",
    "    \n",
    "    print(sum(acc) / len(acc))\n",
    "    print(unpredict/(len(acc)+unpredict))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T11:31:39.384551Z",
     "start_time": "2024-10-29T11:31:39.377926Z"
    }
   },
   "id": "1f8b34f617534650",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'baabbbbaabbaaabbaaabababbabbabbbaabbbababbbbababaaaaaaabaaabbabaabbbaababababaabbaa'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('user_study/user_study_answer.json', 'r', encoding='utf-8') as fa:\n",
    "    answer = json.load(fa)\n",
    "    answer = ['a' if _ else 'b' for _ in answer]\n",
    "''.join(answer)\n",
    "answer = 'baabbbbaab' + 'baaabbaaab' + 'ababbabbab' + 'bbaabbbaba'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T10:37:15.179643Z",
     "start_time": "2024-10-29T10:37:15.162820Z"
    }
   },
   "id": "1ffaaf10653f06c7",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "我做了一个用户研究，给出30个样例以及baseline的结果，和我们提出的方法给出的结果，让志愿者进行判断。其中‘a’代表我们的方法好，‘b’代表baseline的方法好，‘c’则代表无法判断。\n",
    "一共三个用户，给出的判断如下：\n",
    "用户一：'abbaabbaab' + 'baaaabaacc' + 'abbcbabaaa'\n",
    "用户二：'bacbcbbcab' + 'cbabccccbb' + 'ababcabccb'\n",
    "用户三：'cabbccaaab' + 'bcababacab' + 'bacbcacaaa'\n",
    "\n",
    "正确答案为：'baabbbbaab' + 'baaabbaaab' + 'ababbabbab'\n",
    "请帮我分析每个用户的选择，以及利用卡方对三个结果进行一致性和置信度检验"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4ba5bb537c2997b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa between Volunteer 1 and 2: 0.542483660130719\n",
      "Kappa between Volunteer 1 and 3: 0.6428571428571428\n",
      "Kappa between Volunteer 2 and 3: 0.72875226039783\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def wash(lista, listb):\n",
    "    output1 = []\n",
    "    output2 = []\n",
    "    \n",
    "    for x, y in zip(lista, listb):\n",
    "        if x == 'c' or y == 'c':\n",
    "            output1.append(x)\n",
    "            output2.append(x)\n",
    "        else:\n",
    "            output1.append(x)\n",
    "            output2.append(y)\n",
    "    \n",
    "    return output1, output2\n",
    "\n",
    "volunteer1 = 'bbbbbaaaaaaaaabaaaccaabcaaabab'\n",
    "volunteer2 = 'aacacaacaacbabccccbaaaaacaacca'\n",
    "volunteer3 = 'cabaccbaaaacabbaacaabbcacacbab'\n",
    "\n",
    "a, b = wash(list(volunteer1), list(volunteer2))\n",
    "kappa_12 = cohen_kappa_score(a, b)\n",
    "\n",
    "a, b = wash(list(volunteer1), list(volunteer3))\n",
    "kappa_13 = cohen_kappa_score(a, b)\n",
    "\n",
    "a, b = wash(list(volunteer2), list(volunteer3))\n",
    "kappa_23 = cohen_kappa_score(a, b)\n",
    "\n",
    "print(\"Kappa between Volunteer 1 and 2:\", kappa_12)\n",
    "print(\"Kappa between Volunteer 1 and 3:\", kappa_13)\n",
    "print(\"Kappa between Volunteer 2 and 3:\", kappa_23)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T11:49:35.339330Z",
     "start_time": "2024-10-29T11:49:35.331166Z"
    }
   },
   "id": "500da3ea057d56d6",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "|"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "361581e21c304009"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
